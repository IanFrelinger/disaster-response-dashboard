# Disaster Response Dashboard - Corrected Video Narration
# Based on Video presentation plan.pdf - 4-Minute Demo Timeline

metadata:
  title: "Disaster Response Dashboard Demo"
  duration: 240  # 4 minutes total
  language: "en-US"
  voice_provider: "elevenlabs"
  voice_settings:
    speed: 1.0
    pitch: 0
    volume: 1.0

scenes:
  - id: "intro"
    title: "Introduction"
    duration: 15
    narration: "Hi, I'm excited to share my Palantir Building Challenge project. I've built a disaster-response platform that helps commanders and teams coordinate faster and safer in crisis situations."
    voice: "alloy"
    emphasis: "excited, disaster-response, commanders, coordinate, faster, safer"
    
  - id: "problem-statement"
    title: "Problem Statement & Motivation"
    duration: 25
    narration: "Today's emergency responders juggle radios, maps and spreadsheets, which slows decision-making when every minute counts. In many cases, lower-level responders lack access to high-level situational awareness and tools reserved for commanders. I wanted to build something that brings everyone onto the same page without overwhelming them with data."
    voice: "alloy"
    emphasis: "juggle, slows, minute, lack, awareness, same, overwhelming"
    
  - id: "user-persona"
    title: "Target User Persona"
    duration: 15
    narration: "This system is designed for Incident Commanders, Operations and Planning chiefs, dispatchers and field units. It keeps the commander at the top of the chain of command but also empowers front-line teams with real-time information and AI-generated recommendations."
    voice: "alloy"
    emphasis: "designed, commanders, chiefs, dispatchers, units, empowers, real-time, AI"
    
  - id: "technical-architecture"
    title: "Technical Architecture & API Data Flow"
    duration: 30
    narration: "On the front end, I used React and Mapbox to create a fast, 3-D map interface. The backend is Python/Flask with WebSockets and Celery for real-time updates. All of this sits on Palantir Foundry, which streams live data from NOAA, NASA and USGS and powers the AIP assistant. To illustrate how the backend components interact, I built this API data-flow diagram. External feeds—such as NASA FIRMS, NOAA weather and 911 calls—flow into the ingestion and hazard-processing layer. From there, data drives three core services: route optimisation, ontology and entities, and AI decision support. Arrows show how these processors push information to public endpoints and internal/fusion endpoints. By focusing on relevant components and showing clear interaction paths, the diagram remains readable and actionable."
    voice: "alloy"
    emphasis: "React, Mapbox, Python, Flask, WebSockets, Celery, Foundry, NOAA, NASA, USGS, AIP, API, data-flow, external, feeds, ingestion, processing, route, ontology, AI, endpoints, interaction"
    
  - id: "detect-verify"
    title: "Detect & Verify"
    duration: 15
    narration: "Here, a satellite feed shows a new fire. The system flags it and scores the risk based on population and weather. As the commander, I confirm that this is a real incident."
    voice: "alloy"
    emphasis: "satellite, feed, fire, flags, scores, risk, population, weather, commander, confirm, real, incident"
    
  - id: "triage-risk"
    title: "Triage & Risk Scoring"
    duration: 10
    narration: "Based on risk and wind direction, I choose to evacuate rather than shelter in place. The AI suggests this because the fire is near critical infrastructure."
    voice: "alloy"
    emphasis: "risk, wind, direction, evacuate, shelter, AI, suggests, fire, critical, infrastructure"
    
  - id: "define-zones"
    title: "Define Zones"
    duration: 10
    narration: "Using the drawing tool, I outline the evacuation zone and set its priority. This defines which buildings and residents are affected."
    voice: "alloy"
    emphasis: "drawing, tool, outline, evacuation, zone, priority, defines, buildings, residents, affected"
    
  - id: "plan-routes"
    title: "Plan Routes"
    duration: 20
    narration: "I select a route profile—civilian, EMS, fire tactical or police. Each balances safety versus speed. The blue line you see is a hazard-aware route calculated using A* search."
    voice: "alloy"
    emphasis: "select, route, profile, civilian, EMS, fire, tactical, police, balances, safety, speed, blue, line, hazard-aware, calculated, A* search"
    
  - id: "assign-units"
    title: "Assign Units & Track Assets"
    duration: 10
    narration: "Next, I assign engines and medics. Dragging units onto the map updates their tasks and travel times. On the right, you can see building status—evacuated, in progress or refused."
    voice: "alloy"
    emphasis: "assign, engines, medics, dragging, units, map, updates, tasks, travel, times, building, status, evacuated, progress, refused"
    
  - id: "ai-support"
    title: "AI Support & Replan"
    duration: 20
    narration: "I can ask the AIP assistant questions like 'What if we lose Highway 30?' and immediately get alternative routes. If a new hazard or weather update comes in, the system automatically recalculates and loops back to zone definition."
    voice: "alloy"
    emphasis: "ask, AIP, assistant, questions, lose, Highway, immediately, alternative, routes, hazard, weather, update, automatically, recalculates, loops, zone, definition"
    
  - id: "value-proposition"
    title: "Value Proposition & Impact"
    duration: 30
    narration: "This platform speeds up decisions, reduces staffing needed for manual data fusion, and gives every responder a common operating picture while keeping the commander firmly in control. By automating routine steps, it allows teams to focus on actions that save lives and property."
    voice: "alloy"
    emphasis: "speeds, decisions, reduces, staffing, manual, data, fusion, responder, common, operating, picture, commander, control, automating, routine, teams, focus, actions, save, lives, property"
    
  - id: "foundry-integration"
    title: "Foundry Integration & AI Assistance"
    duration: 20
    narration: "Thanks to Foundry's data pipelines and ontology, I was able to ingest and fuse multiple feeds quickly. The AIP assistant is context-aware because it sits on top of that ontology, so it can offer recommendations like rerouting around a blocked highway or predicting fire spread."
    voice: "alloy"
    emphasis: "Foundry, data, pipelines, ontology, ingest, fuse, multiple, feeds, quickly, AIP, assistant, context-aware, sits, ontology, recommendations, rerouting, blocked, highway, predicting, fire, spread"
    
  - id: "conclusion"
    title: "Conclusion & Call to Action"
    duration: 20
    narration: "In summary, this project demonstrates how we can modernize emergency response by combining real-time data, AI assistance and a simplified chain of command. I'm excited to discuss how this could be piloted with your teams."
    voice: "alloy"
    emphasis: "summary, project, demonstrates, modernize, emergency, response, combining, real-time, data, AI, assistance, simplified, chain, command, excited, discuss, piloted, teams"

voice_providers:
  openai:
    model: "gpt-4o-mini-tts"
    voice: "alloy"
    speed: 1.0
    api_key_env: "OPENAI_API_KEY"
    
  elevenlabs:
    voice_id: "LIpBYrITLsIquxoXdSkr"  # Cloned voice ID from config
    stability: 0.5
    similarity_boost: 0.75
    api_key_env: "ELEVEN_API_KEY"
    
  azure:
    voice: "en-US-JennyNeural"
    region: "eastus"
    api_key_env: "AZURE_SPEECH_KEY"
    region_env: "AZURE_SPEECH_REGION"
    
  piper:
    voice: "en_US-amy-low.onnx"
    model_path: "./voices/en_US-amy-low.onnx"
    config_path: "./voices/en_US-amy-low.onnx.json"
    speed: 1.0
    noise_scale: 0.667
    length_scale: 1.0
    noise_w: 0.8

audio_settings:
  sample_rate: 44100
  bit_depth: 16
  channels: 1
  format: "wav"
  normalization: "loudness"
  target_lufs: -23.0
  true_peak: -1.0
  
  processing:
    noise_reduction: true
    compression: true
    equalization: true
    reverb: false
    
  output:
    per_scene: "audio/vo/"
    merged: "audio/voiceover.wav"
    subtitles: "subs/vo.srt"
